# 13.Shuffle调优之HashShuffleManager与SortShuffleManager

参数：
~~spark.shuffle.manager：hash、sort、tungsten-sort~~（自己实现内存管理,2.4该参数取消）
spark.shuffle.sort.bypassMergeThreshold：200

> Spark 1.1 引入Sort Based Shuffle，但默认仍为Hash Based Shuffle
Spark 1.2 默认的Shuffle方式改为Sort Based Shuffle
Spark 1.4 引入Tungsten-Sort Based Shuffle
Spark 1.6 Tungsten-sort并入Sort Based Shuffle
Spark 2.0 Hash Based Shuffle退出历史舞台

#### SortShuffleManager与~~HashShuffleManager~~两点不同：

1. SortShuffleManager会对每个reduce task要处理的数据，进行排序（默认的）。
2. SortShuffleManager会避免像HashShuffleManager那样，默认就去创建多份磁盘文件。<u>一个task，只会写入一个磁盘文件，不同reduce task的数据，用offset来划分界定</u>

在spark 1.5.x以后，对于shuffle manager又出来了一种新的manager，tungsten-sort（钨丝），钨丝sort shuffle manager。官网上一般说，钨丝sort shuffle manager，效果跟sort shuffle manager是差不多的。

但是，唯一的不同之处在于，钨丝manager，是使用了自己实现的一套内存管理机制，性能上有很大的提升， 而且可以避免shuffle过程中产生的大量的OOM，GC，等等内存相关的异常。

#### spark.shuffle.sort.bypassMergeThreshold=200
自己可以设定一个阈值，默认是200，当reduce task数量少于等于200；map task创建的输出文件小于等于200的；最后会将所有的输出文件合并为一份文件。

这样做的好处，就是避免了sort排序，节省了性能开销。而且还能将多个reduce task的文件合并成一份文件。节省了reduce task拉取数据的时候的磁盘IO的开销。
