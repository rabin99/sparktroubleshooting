# 26.troubleshooting之错误的持久化方式以及checkpoint的使用

#### 错误的持久化使用方式：

usersRDD，想要对这个RDD做一个cache，希望能够在后面多次使用这个RDD的时候，不用反复重新计算RDD；可以直接使用通过各个节点上的executor的BlockManager管理的内存 / 磁盘上的数据，避免重新反复计算RDD。
```java
usersRDD.cache()   // 这种方法是错误的使用！！！
usersRDD.count()
usersRDD.take()
```
上面这种方式，不要说会不会生效了，实际上是会报错的。会报什么错误呢？会报一大堆file not found的错误。

正确的持久化使用方式：
```java
// 通过一系列计算得到usersRDD
usersRDD = usersRDD.cache()
val cachedUsersRDD = usersRDD.cache()
```
之后再去使用usersRDD，或者cachedUsersRDD，就可以了。就不会报错了。所以说，这个是咱们的持久化的正确的使用方式。

#### 原理
持久化，大多数时候，都是会正常工作的。但是就怕，有些时候，会出现意外。

比如说，缓存在内存中的数据，可能莫名其妙就丢失掉了。

或者说，存储在磁盘文件中的数据，莫名其妙就没了，文件被误删了。


出现上述情况的时候，接下来，如果要对这个RDD执行某些操作，可能会发现RDD的某个partition找不到了。

对消失的partition重新计算，计算完以后再缓存和使用。

有些时候，计算某个RDD，可能是极其耗时的。可能RDD之前有大量的父RDD。那么如果你要重新计算一个partition，可能要重新计算之前所有的父RDD对应的partition。

这种情况下，就可以选择对这个RDD进行checkpoint，以防万一。进行checkpoint，就是说，会将RDD的数据，持久化一份到容错的文件系统上（比如hdfs）。

在对这个RDD进行计算的时候，如果发现它的缓存数据不见了。优先就是先找一下有没有checkpoint数据（到hdfs上面去找）。如果有的话，就使用checkpoint数据了。不至于说是去重新计算。

checkpoint，其实就是可以作为是cache的一个备胎。如果cache失效了，checkpoint就可以上来使用了。

checkpoint有利有弊，利在于，提高了spark作业的可靠性，一旦发生问题，还是很可靠的，不用重新计算大量的rdd；但是弊在于，进行checkpoint操作的时候，也就是将rdd数据写入hdfs中的时候，还是会消耗性能的。

checkpoint，用性能换可靠性。

#### checkpoint原理：

1、在代码中，用SparkContext，设置一个checkpoint目录，可以是一个容错文件系统的目录，比如hdfs；
2、在代码中，对需要进行checkpoint的rdd，执行RDD.checkpoint()；
3、RDDCheckpointData（spark内部的API），接管你的RDD，会标记为marked for checkpoint，准备进行checkpoint
4、你的job运行完之后，会调用一个finalRDD.doCheckpoint()方法，会顺着rdd lineage，回溯扫描，发现有标记为待checkpoint的rdd，就会进行二次标记，inProgressCheckpoint，正在接受checkpoint操作
5、job执行完之后，就会启动一个内部的新job，去将标记为inProgressCheckpoint的rdd的数据，都写入hdfs文件中。（备注，如果rdd之前cache过，会直接从缓存中获取数据，写入hdfs中；如果没有cache过，那么就会重新计算一遍这个rdd，再checkpoint）
6、将checkpoint过的rdd之前的依赖rdd，改成一个CheckpointRDD*，强制改变你的rdd的lineage。后面如果rdd的cache数据获取失败，直接会通过它的上游CheckpointRDD，去容错的文件系统，比如hdfs，中，获取checkpoint的数据。

#### checkpoint的使用

1. SparkContext，设置checkpoint目录
2. rdd进行checkpoint之前强烈建议先对rdd进行cache
3. 对RDD执行checkpoint操作

### cache、persist和checkpoint区别
都是trunsformation操作。cache、persist重用RDD

cache只缓存到memory,底层调用persist(MEMORY_ONLY），persist可以设置持久化级别。
cache使用完毕后，调用unpersist释放，否则一直占用，浪费内存。
cache后，lineage会被保留。
cache机制是没计算出一个要cache的partition就直接将其cache到内存。
checkpoint需要等job结束后，另外启动专门的job去完成checkpint

如果是persist（StorageLevel.DISK_ONLY）与checkpoint也是有区别的。
rdd persist持久化到到磁盘，partitino是由blockManager不按理，一旦Driver Program结束，磁盘的rdd会被清空（BlockManager使用的local文件夹会被删除）

checkpoint持久化到checkpointDir的数据在程序结束后继续存在！除非手动/程序发起删除。
checkpoint的RDD lineage会被删除，因为单独起job执行checkpoint操作，所以强烈建议先把RDD持久化到内存！